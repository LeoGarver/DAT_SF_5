{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Import the usual packages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read the csv and create a Pandas dataframe for analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = pd.read_csv('iris_data.csv',names= ['SepalLength','SepalWidth','PetalLength','PetalWidth','TargetNames','Target'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(iris)):\n",
      "    if iris['TargetNames'][i]== 'Iris-setosa':\n",
      "        iris['Target'][i]=0\n",
      "    elif iris['TargetNames'][i]== 'Iris-versicolor':\n",
      "        iris['Target'][i]=1\n",
      "    elif iris['TargetNames'][i]== 'Iris-virginica':\n",
      "        iris['Target'][i]=2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = iris.dropna(how='any')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x= iris[['SepalLength','SepalWidth','PetalLength','PetalWidth']]\n",
      "Names= iris[['TargetNames']]\n",
      "y = iris[['Target']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Implement KNN classification, using the sklearn package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn = KNeighborsClassifier(3).fit(x_train,y_train.ravel())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn.score(x_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Implement cross-validation for your KNN classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X= x.values\n",
      "Y= y.values.ravel()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_validate(x, y, classifier, k_fold) :\n",
      "\n",
      "    # derive a set of (random) training and testing indices\n",
      "    k_fold_indices = KFold( len(x), n_folds=k_fold,\n",
      "                           indices=True, shuffle=True,\n",
      "                           random_state=0)\n",
      "\n",
      "    k_score_total = 0\n",
      "    # for each training and testing slices run the classifier, and score the results\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "        model = classifier(x[[ train_slice  ]],\n",
      "                         y[[ train_slice  ]])\n",
      "\n",
      "        k_score = model.score(x[[ test_slice ]],\n",
      "                              y[[ test_slice ]])\n",
      "\n",
      "        k_score_total += k_score\n",
      "\n",
      "    # return the average accuracy\n",
      "    return k_score_total/k_fold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X, Y, KNeighborsClassifier(3).fit, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "0.95333333333333337"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Use your KNN classifier and cross-validation code from (1) and (2) above to determine the optimal value of K (number of nearest neighbors to consult) for this Iris dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kscores={i+1:cross_validate(X, Y, KNeighborsClassifier(i+1).fit, 5) for i in range(len(iris))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kscores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "{1: 0.95999999999999996,\n",
        " 2: 0.94000000000000006,\n",
        " 3: 0.95333333333333337,\n",
        " 4: 0.95999999999999996,\n",
        " 5: 0.95999999999999996,\n",
        " 6: 0.95333333333333337,\n",
        " 7: 0.95333333333333337,\n",
        " 8: 0.95999999999999996,\n",
        " 9: 0.95999999999999996,\n",
        " 10: 0.95999999999999996,\n",
        " 11: 0.96666666666666656,\n",
        " 12: 0.95999999999999996,\n",
        " 13: 0.95999999999999996,\n",
        " 14: 0.95333333333333337,\n",
        " 15: 0.96666666666666656,\n",
        " 16: 0.94666666666666666,\n",
        " 17: 0.94666666666666666,\n",
        " 18: 0.94000000000000006,\n",
        " 19: 0.94666666666666666,\n",
        " 20: 0.94666666666666666,\n",
        " 21: 0.94666666666666666,\n",
        " 22: 0.95333333333333337,\n",
        " 23: 0.94666666666666666,\n",
        " 24: 0.94666666666666666,\n",
        " 25: 0.94000000000000006,\n",
        " 26: 0.94666666666666666,\n",
        " 27: 0.94000000000000006,\n",
        " 28: 0.94666666666666666,\n",
        " 29: 0.94666666666666666,\n",
        " 30: 0.94000000000000006,\n",
        " 31: 0.94000000000000006,\n",
        " 32: 0.92666666666666675,\n",
        " 33: 0.94000000000000006,\n",
        " 34: 0.94000000000000006,\n",
        " 35: 0.93333333333333335,\n",
        " 36: 0.93333333333333335,\n",
        " 37: 0.93333333333333335,\n",
        " 38: 0.93333333333333335,\n",
        " 39: 0.92666666666666675,\n",
        " 40: 0.92666666666666675,\n",
        " 41: 0.92666666666666675,\n",
        " 42: 0.92666666666666675,\n",
        " 43: 0.92666666666666675,\n",
        " 44: 0.92666666666666675,\n",
        " 45: 0.92666666666666675,\n",
        " 46: 0.91333333333333344,\n",
        " 47: 0.91333333333333344,\n",
        " 48: 0.90666666666666662,\n",
        " 49: 0.91333333333333344,\n",
        " 50: 0.90666666666666662,\n",
        " 51: 0.91333333333333344,\n",
        " 52: 0.91333333333333344,\n",
        " 53: 0.91333333333333344,\n",
        " 54: 0.91333333333333344,\n",
        " 55: 0.90666666666666684,\n",
        " 56: 0.90000000000000013,\n",
        " 57: 0.90666666666666684,\n",
        " 58: 0.89333333333333331,\n",
        " 59: 0.91333333333333344,\n",
        " 60: 0.89333333333333331,\n",
        " 61: 0.90000000000000002,\n",
        " 62: 0.88666666666666671,\n",
        " 63: 0.88666666666666671,\n",
        " 64: 0.88000000000000012,\n",
        " 65: 0.88000000000000012,\n",
        " 66: 0.88000000000000012,\n",
        " 67: 0.88000000000000012,\n",
        " 68: 0.87333333333333341,\n",
        " 69: 0.8600000000000001,\n",
        " 70: 0.81333333333333346,\n",
        " 71: 0.79333333333333345,\n",
        " 72: 0.81333333333333346,\n",
        " 73: 0.80666666666666664,\n",
        " 74: 0.71999999999999997,\n",
        " 75: 0.69333333333333325,\n",
        " 76: 0.68666666666666676,\n",
        " 77: 0.67999999999999994,\n",
        " 78: 0.68000000000000005,\n",
        " 79: 0.65333333333333343,\n",
        " 80: 0.55333333333333334,\n",
        " 81: 0.55333333333333334,\n",
        " 82: 0.55333333333333334,\n",
        " 83: 0.55333333333333334,\n",
        " 84: 0.55333333333333334,\n",
        " 85: 0.55999999999999994,\n",
        " 86: 0.55999999999999994,\n",
        " 87: 0.55333333333333334,\n",
        " 88: 0.55333333333333334,\n",
        " 89: 0.55333333333333334,\n",
        " 90: 0.55333333333333334,\n",
        " 91: 0.55333333333333334,\n",
        " 92: 0.55333333333333334,\n",
        " 93: 0.54666666666666663,\n",
        " 94: 0.54666666666666663,\n",
        " 95: 0.54666666666666663,\n",
        " 96: 0.53999999999999992,\n",
        " 97: 0.53999999999999992,\n",
        " 98: 0.53999999999999992,\n",
        " 99: 0.53999999999999992,\n",
        " 100: 0.53999999999999992,\n",
        " 101: 0.53999999999999992,\n",
        " 102: 0.53999999999999992,\n",
        " 103: 0.53999999999999992,\n",
        " 104: 0.53999999999999992,\n",
        " 105: 0.53999999999999992,\n",
        " 106: 0.53999999999999992,\n",
        " 107: 0.52666666666666662,\n",
        " 108: 0.52666666666666662,\n",
        " 109: 0.51333333333333331,\n",
        " 110: 0.5066666666666666,\n",
        " 111: 0.5066666666666666,\n",
        " 112: 0.49333333333333335,\n",
        " 113: 0.49333333333333335,\n",
        " 114: 0.49333333333333335,\n",
        " 115: 0.45999999999999996,\n",
        " 116: 0.37333333333333335,\n",
        " 117: 0.35333333333333333,\n",
        " 118: 0.35333333333333333,\n",
        " 119: 0.35333333333333333,\n",
        " 120: 0.23999999999999999,\n",
        " 121: 0.23999999999999999,\n",
        " 122: 0.23999999999999999,\n",
        " 123: 0.23999999999999999,\n",
        " 124: 0.23999999999999999,\n",
        " 125: 0.23999999999999999,\n",
        " 126: 0.23999999999999999,\n",
        " 127: 0.23999999999999999,\n",
        " 128: 0.23999999999999999,\n",
        " 129: 0.23999999999999999,\n",
        " 130: 0.23999999999999999,\n",
        " 131: 0.23999999999999999,\n",
        " 132: 0.23999999999999999,\n",
        " 133: 0.23999999999999999,\n",
        " 134: 0.23999999999999999,\n",
        " 135: 0.23999999999999999,\n",
        " 136: 0.23999999999999999,\n",
        " 137: 0.23999999999999999,\n",
        " 138: 0.23999999999999999,\n",
        " 139: 0.23999999999999999,\n",
        " 140: 0.23999999999999999,\n",
        " 141: 0.23999999999999999,\n",
        " 142: 0.23999999999999999,\n",
        " 143: 0.23999999999999999,\n",
        " 144: 0.23999999999999999,\n",
        " 145: 0.23999999999999999,\n",
        " 146: 0.23999999999999999,\n",
        " 147: 0.23999999999999999,\n",
        " 148: 0.23999999999999999,\n",
        " 149: 0.23999999999999999,\n",
        " 150: 0.23999999999999999}"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bestk=0\n",
      "maxv=0\n",
      "for k, v in kscores.iteritems():\n",
      "    if v>maxv:\n",
      "        maxv=v\n",
      "        bestk=k\n",
      "print bestk, maxv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##4. Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range of K that you consider interesting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.suptitle('K vs Cross Validation accuracy', fontsize=14)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "<matplotlib.text.Text at 0x19bf2eb8>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x19bceb00>"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(kscores.keys(), kscores.values(), c='b', marker='o',)\n",
      "plt.xlim(-1,80)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD7CAYAAACVMATUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGOpERBrCUCci0hCGOhGRhvw/3p3pt/2ZzNkAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x19e94be0>"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The accuracy of the KNN classification seems to be highest with K in the 4-15 range. Then the accuracy slowly delcines until K~ 65, and then the accuracy declines very quickly"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##5. OPTIONAL BONUS QUESTION: Using the value of K obtained in (3) above, vary the number of folds used for cross-validation across an interesting range, e.g. [ 2, 3, 5, 6, 10, 15]. How does classifier accuracy vary with the number of folds used? Do you think there exists an optimal number of folds to use for this particular problem? Why or why not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numfolds=[2,3,5,6,10,15,25]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foldscores={numfolds[i]:cross_validate(X, Y, KNeighborsClassifier(11).fit, numfolds[i]) for i in range(len(numfolds))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foldscores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "{2: 0.95333333333333337,\n",
        " 3: 0.96666666666666667,\n",
        " 5: 0.96666666666666656,\n",
        " 6: 0.96666666666666667,\n",
        " 10: 0.95999999999999996,\n",
        " 15: 0.96666666666666667,\n",
        " 25: 0.96666666666666656}"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The classifier accuracy does not seem to vary greatly with the different number of folds. I think the reason that there is so little difference with this problem is because the iris dataset is fairly predictable and does not contain many outliers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}